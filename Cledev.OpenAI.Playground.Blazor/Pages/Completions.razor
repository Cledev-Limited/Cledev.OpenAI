@page "/completions"

@inherits CompletionsPage

<PageTitle>Cledev.OpenAI - Completions</PageTitle>

<h1 class="pb-3 mb-4 border-bottom">Completions</h1>

<p class="mb-4">Given a prompt, the model will return one or more predicted completions, and can also return the probabilities of alternative tokens at each position.</p>

<EditForm Model="Request" OnValidSubmit="OnSubmitAsync">
    <div class="mb-3">
        <InputText id="Prompt" placeholder="Prompt" @bind-Value="Request.Prompt" class="form-control" />
    </div>

    <div class="modal fade" id="optionsModal" tabindex="-1" aria-labelledby="optionsModalLabel" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title" id="optionsModalLabel">Options</h5>
                    <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <div class="row mb-3">
                        <label for="Model" class="col-sm-5 col-form-label">
                            <i class="fa-regular fa-circle-question" href="#" data-bs-toggle="tooltip" data-bs-placement="right" title="Required. ID of the model to use. You can use the List models API to see all of your available models, or see our Model overview for descriptions of them."></i>
                            Model
                        </label>
                        <div class="col-sm-7">
                            <InputSelect id="Model" @bind-Value="Request.Model" class="form-select">
                                @foreach (var item in CompletionModels)
                                {
                                    <option value="@item">@item</option>
                                }
                            </InputSelect>
                        </div>
                    </div>
                    <div class="row mb-3">
                        <label for="Suffix" class="col-sm-5 col-form-label">
                            <i class="fa-regular fa-circle-question" data-bs-toggle="tooltip" data-bs-placement="right" title="Optional (Defaults to null). The suffix that comes after a completion of inserted text."></i>
                            Suffix
                        </label>
                        <div class="col-sm-7">
                            <InputText id="Suffix" @bind-Value="Request.Suffix" class="form-control"/>
                        </div>
                    </div>
                    <div class="row mb-3">
                        <label for="MaxTokens" class="col-sm-5 col-form-label">
                            <i class="fa-regular fa-circle-question" data-bs-toggle="tooltip" data-bs-placement="right" title="Optional (Defaults to 16). The maximum number of tokens to generate in the completion. The token count of your prompt plus max_tokens cannot exceed the model's context length. Most models have a context length of 2048 tokens (except for the newest models, which support 4096)."></i>
                            Max Tokens
                        </label>
                        <div class="col-sm-7">
                            <InputNumber id="MaxTokens" @bind-Value="Request.MaxTokens" class="form-control"/>
                        </div>
                    </div>                    
                    <div class="row mb-3">
                        <label for="Temperature" class="col-sm-5 col-form-label">
                            <i class="fa-regular fa-circle-question" data-bs-toggle="tooltip" data-bs-placement="right" title="Optional (Defaults to 1). What sampling temperature to use. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer. We generally recommend altering this or top_p but not both."></i>
                            Temperature
                        </label>
                        <div class="col-sm-7">
                            <InputNumber id="Temperature" @bind-Value="Request.Temperature" @bind-Value:format="F2" class="form-control"/>
                        </div>
                    </div>
                    <div class="row mb-3">
                        <label for="TopP" class="col-sm-5 col-form-label">
                            <i class="fa-regular fa-circle-question" data-bs-toggle="tooltip" data-bs-placement="right" title="Optional (Defaults to 1). An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or temperature but not both."></i>
                            TopP
                        </label>
                        <div class="col-sm-7">
                            <InputNumber id="TopP" @bind-Value="Request.TopP" @bind-Value:format="F2" class="form-control"/>
                        </div>
                    </div>
                    <div class="row mb-3">
                        <label for="N" class="col-sm-5 col-form-label">
                            <i class="fa-regular fa-circle-question" data-bs-toggle="tooltip" data-bs-placement="right" title="Optional (Defaults to 1). How many completions to generate for each prompt. Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop."></i>
                            N
                        </label>
                        <div class="col-sm-7">
                            <InputNumber id="N" @bind-Value="Request.N" class="form-control" />
                        </div>
                    </div>
                    <div class="row mb-3 align-items-center">
                        <label for="Stream" class="col-sm-5 col-form-label">
                            <i class="fa-regular fa-circle-question" data-bs-toggle="tooltip" data-bs-placement="right" title="Optional (Defaults to false). Whether to stream back partial progress. If set, tokens will be sent as data-only server-sent events as they become available, with the stream terminated by a data: [DONE] message."></i>
                            Stream
                        </label>
                        <div class="col-sm-7">
                            <InputCheckbox id="Stream" @bind-Value="Request.Stream" class="form-check-input" />
                        </div>
                    </div>
                    <div class="row mb-3">
                        <label for="LogProbs" class="col-sm-5 col-form-label">
                            <i class="fa-regular fa-circle-question" data-bs-toggle="tooltip" data-bs-placement="right" title="Optional (Defaults to null). Include the log probabilities on the logprobs most likely tokens, as well the chosen tokens. For example, if logprobs is 5, the API will return a list of the 5 most likely tokens. The API will always return the logprob of the sampled token, so there may be up to logprobs+1 elements in the response. The maximum value for logprobs is 5. If you need more than this, please contact us through our Help center and describe your use case."></i>
                            Log Probs
                        </label>
                        <div class="col-sm-7">
                            <InputNumber id="LogProbs" @bind-Value="Request.LogProbs" class="form-control" />
                        </div>
                    </div>
                    <div class="row mb-3 align-items-center">
                        <label for="Echo" class="col-sm-5 col-form-label">
                            <i class="fa-regular fa-circle-question" data-bs-toggle="tooltip" data-bs-placement="right" title="Optional (Defaults to false). Echo back the prompt in addition to the completion."></i>
                            Echo
                        </label>
                        <div class="col-sm-7">
                            <InputCheckbox id="Echo" @bind-Value="Request.Echo" class="form-check-input" />
                        </div>
                    </div>
                    <div class="row mb-3">
                        <label for="Stop" class="col-sm-5 col-form-label">
                            <i class="fa-regular fa-circle-question" data-bs-toggle="tooltip" data-bs-placement="right" title="Optional (Defaults to null). Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence."></i>
                            Stop
                        </label>
                        <div class="col-sm-7">
                            <InputText id="Stop" @bind-Value="Request.Stop" class="form-control"/>
                        </div>
                    </div>
                    <div class="row mb-3">
                        <label for="PresencePenalty" class="col-sm-5 col-form-label">
                            <i class="fa-regular fa-circle-question" data-bs-toggle="tooltip" data-bs-placement="right" title="Optional (Defaults to 0). Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics."></i>
                            Presence Penalty
                        </label>
                        <div class="col-sm-7">
                            <InputNumber id="PresencePenalty" @bind-Value="Request.PresencePenalty" @bind-Value:format="F2" class="form-control"/>
                        </div>
                    </div>
                    <div class="row mb-3">
                        <label for="FrequencyPenalty" class="col-sm-5 col-form-label">
                            <i class="fa-regular fa-circle-question" data-bs-toggle="tooltip" data-bs-placement="right" title="Optional (Defaults to 0). Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim."></i>
                            Frequency Penalty
                        </label>
                        <div class="col-sm-7">
                            <InputNumber id="FrequencyPenalty" @bind-Value="Request.FrequencyPenalty" @bind-Value:format="F2" class="form-control"/>
                        </div>
                    </div>
                    <div class="row mb-3">
                        <label for="BestOf" class="col-sm-5 col-form-label">
                            <i class="fa-regular fa-circle-question" data-bs-toggle="tooltip" data-bs-placement="right" title="Optional (Defaults to 1). Generates best_of completions server-side and returns the best (the one with the highest log probability per token). Results cannot be streamed. When used with n, best_of controls the number of candidate completions and n specifies how many to return – best_of must be greater than n. Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop."></i>
                            Best Of
                        </label>
                        <div class="col-sm-7">
                            <InputNumber id="BestOf" @bind-Value="Request.BestOf" class="form-control"/>
                        </div>
                    </div>
                    <div class="row mb-3">
                        <label for="LogitBias" class="col-sm-5 col-form-label">
                            <i class="fa-regular fa-circle-question" data-bs-toggle="tooltip" data-bs-placement="right" title="Optional (Defaults to null). Modify the likelihood of specified tokens appearing in the completion. Accepts a json object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this tokenizer tool (which works for both GPT-2 and GPT-3) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token. As an example, you can pass {'50256': -100} to prevent the &amp;lt;|endoftext|&amp;rt; token from being generated."></i>
                            Logit Bias
                        </label>
                        <div class="col-sm-7">
                            <InputTextArea id="LogitBias" @bind-Value="Request.LogitBias" class="form-control" />
                        </div>
                    </div>
                    <div class="row">
                        <label for="User" class="col-sm-5 col-form-label">
                            <i class="fa-regular fa-circle-question" data-bs-toggle="tooltip" data-bs-placement="right" title="Optional. A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse."></i>
                            User
                        </label>
                        <div class="col-sm-7">
                            <InputText id="User" @bind-Value="Request.User" class="form-control" />
                        </div>
                    </div>
                </div>
                <div class="modal-footer">
                    <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Close</button>
                </div>
            </div>
        </div>
    </div>

    @if (IsLoading)
    {
        <button class="btn btn-primary text-nowrap" type="button" disabled>
            <span class="spinner-border spinner-border-sm" role="status" aria-hidden="true"></span>
            Creating Completion...
        </button>
        <button type="button" class="btn btn-outline-secondary" disabled>Options</button>
    }
    else
    {
        <button type="submit" class="btn btn-primary">Create Completion</button>
        <button type="button" class="btn btn-outline-secondary" data-bs-toggle="modal" data-bs-target="#optionsModal">Options</button>
    }
</EditForm>

@if (Response is not null && Error is null)
{
    <div class="row my-4">
        <div class="col-6">
            <h4>Response</h4>

            @for (var index = 0; index < Response.Choices.Count; index++)
            {
                var choice = Response.Choices[index];
                <div class="card d-flex mt-3">
                    <div class="card-header">
                        Choice @(index + 1)
                    </div>
                    <div class="card-body">
                        <div class="mb-3">@choice.Text</div>
                        <span class="fw-bold">Index</span>: @choice.Index<br />
                        <span class="fw-bold">Finish Reason</span>: @choice.FinishReason<br />
                        <span class="fw-bold">Log Probs</span>: @choice.LogProbs
                    </div>
                </div>
            }

            <div class="card d-flex mt-3">
                <div class="card-header">
                    Info
                </div>
                <div class="card-body">
                    <span class="fw-bold">Id</span>: @Response.Id<br />
                    <span class="fw-bold">Object</span>: @Response.Object<br />
                    <span class="fw-bold">Created</span>: @Response.Created<br />
                    <span class="fw-bold">Model</span>: @Response.Model
                </div>
            </div>
            
            @if (Response.Usage is not null)
            {
                <div class="card d-flex mt-3">
                    <div class="card-header">
                        Usage
                    </div>
                    <div class="card-body">
                        <span class="fw-bold">Prompt Tokens</span>: @Response.Usage.PromptTokens<br />
                        <span class="fw-bold">Completion Tokens</span>: @Response.Usage.CompletionTokens<br />
                        <span class="fw-bold">Total Tokens</span>: @Response.Usage.TotalTokens
                    </div>
                </div>
            }
        </div>
    </div>
}

<Error Model="Error"></Error>
